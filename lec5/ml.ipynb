{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchaudio import load, transforms\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.MFCC(sample_rate=8000)\n",
    "\n",
    "def normalize(tensor):\n",
    "    tensor_minusmean = tensor - tensor.mean()\n",
    "    return tensor_minusmean / tensor_minusmean.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavDataset(Dataset):\n",
    "    def __init__(self, data_folder, length=300000, transform=None):\n",
    "        self.data_folder = data_folder\n",
    "        self.dim = length\n",
    "        self.wav_list = []\n",
    "        self.transform = transform\n",
    "\n",
    "        formats = [\".wav\", \".WAV\"]\n",
    "        for root, dirnames, filenames in os.walk(data_folder):\n",
    "            for filename in filenames:\n",
    "                if os.path.splitext(filename)[1] in formats:\n",
    "                    label = str(root).split(\"/\")[-1]\n",
    "                    self.wav_list.append([os.path.join(root, filename), label])\n",
    "\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        filename, label = self.wav_list[item]\n",
    "        wb_wav, sr = load(filename)\n",
    "        wb_wav = wb_wav[0, :] # 单声道\n",
    "\n",
    "        length = len(wb_wav)\n",
    "        if length >= self.dim:\n",
    "               max_audio_start = length - self.dim\n",
    "               audio_start = np.random.randint(0, max_audio_start)\n",
    "               wb_wav = wb_wav[audio_start: audio_start + self.dim]\n",
    "        else:\n",
    "            wb_wav = F.pad(wb_wav, (0, self.dim - length), \"constant\")\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            wb_wav = normalize(self.transform(wb_wav))\n",
    "\n",
    "        return wb_wav, sr, filename, label\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.wav_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
